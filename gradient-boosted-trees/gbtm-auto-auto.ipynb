{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow_decision_forests as tfdf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_iteration: ith model developed\n",
    "num_trials: number of trials the model goes through during auto hyperparameter tuning\n",
    "\"\"\"\n",
    "\n",
    "train_iteration = 1\n",
    "num_trials = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in the train data\n",
    "\"\"\"\n",
    "df = pd.read_csv('../data/adult.train.csv', header=0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Remove missing values\n",
    "\"\"\"\n",
    "df.replace(' ?', pd.NA, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Remove duplicates\n",
    "\"\"\"\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Print out the unique values\n",
    "\"\"\"\n",
    "df_unique_values = pd.DataFrame(columns=['unique_values', 'count'])\n",
    "for col in df.columns:\n",
    "    df_unique_values.loc[col] = [df[col].unique(), df[col].nunique()]\n",
    "\n",
    "df_unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Categorize the column values to integers\n",
    "\"\"\"\n",
    "def categorize_column(df, col):\n",
    "    unique_values = df[col].unique()\n",
    "    categories = {}\n",
    "    for i in range(len(unique_values)):\n",
    "        categories[unique_values[i]] = i\n",
    "    df[col] = df[col].map(categories)\n",
    "    return df\n",
    "\n",
    "for col in df.columns:\n",
    "    df = categorize_column(df, col)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "One-hot encoding for cateogorical features\n",
    "\"\"\"\n",
    "# df = pd.get_dummies(df, columns=['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'])\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Verify the number of unique values\n",
    "\"\"\"\n",
    "df_min_max = pd.DataFrame(columns=['min', 'max'])\n",
    "for col in df.columns:\n",
    "    df_min_max.loc[col] = [df[col].min(), df[col].max()]\n",
    "\n",
    "df_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initialize the features, drop the target column and the education column because we already have education-num\n",
    "\"\"\"\n",
    "X = df.drop(['salary', 'education'], axis=1)\n",
    "y = df['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in the test data\n",
    "\"\"\"\n",
    "df_test = pd.read_csv('../data/adult.test.csv', header=0)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Remove missing values from test data\n",
    "\"\"\"\n",
    "df_test.replace(' ?', pd.NA, inplace=True)\n",
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Drop duplicates from test data\n",
    "\"\"\"\n",
    "df_test.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Categorize the test data\n",
    "\"\"\"\n",
    "for col in df_test.columns:\n",
    "    df_test = categorize_column(df_test, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initialize the test features, drop the target column and the education column because we already have education-num\n",
    "\"\"\"\n",
    "X_test = df_test.drop(['salary', 'education'], axis=1)\n",
    "y_test = df_test['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combine X and y into a single dataframe for training data and convert to a TensorFlow dataset\n",
    "\"\"\"\n",
    "df_train = pd.concat([X, y], axis=1)\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(df_train, label='salary')\n",
    "\n",
    "\"\"\"\n",
    "Categorize X_test and y_test into a single dataframe for testing data and convert to a TensorFlow dataset\n",
    "\"\"\"\n",
    "df_test = pd.concat([X_test, y_test], axis=1)\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(df_test, label='salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute the class weights to address the class imbalance problems\n",
    "\"\"\"\n",
    "\n",
    "# class_weights = compute_class_weight('balanced', classes=[0, 1], y=y)\n",
    "\n",
    "# class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "# class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "\n",
    "print(sess)\n",
    "\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = tfdf.tuner.RandomSearch(num_trials=num_trials, use_predefined_hps=True)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    tuned_model = tfdf.keras.GradientBoostedTreesModel(tuner=tuner)\n",
    "    # tuned_model.fit(train_ds, verbose=2, class_weight=class_weights_dict) # Run the model with class weights\n",
    "    tuned_model.fit(train_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_logs = tuned_model.make_inspector().tuning_logs()\n",
    "sorted_logs = tuning_logs.sort_values('score', ascending=False)\n",
    "sorted_logs.to_csv(f'../results/gbtm-auto-auto/gbtm-auto-auto-labeled-unweighted-{train_iteration}-LOGS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(tuning_logs[\"score\"], label=\"current trial\")\n",
    "plt.plot(tuning_logs[\"score\"].cummax(), label=\"best trial\")\n",
    "plt.title(f\"gbtm-auto-auto-{train_iteration}\")\n",
    "plt.xlabel(\"Tuning step\")\n",
    "plt.ylabel(\"Tuning score\")\n",
    "plt.legend()\n",
    "plt.savefig(f'../results/gbtm-auto-auto/gbtm-auto-auto-labeled-unweighted-{train_iteration}-LOGS.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tuned_model.predict(test_ds)\n",
    "print(predictions)\n",
    "\n",
    "# make predictions binary\n",
    "predictions = [1 if prediction > 0.5 else 0 for prediction in predictions]\n",
    "\n",
    "# add new row 'predictions' to test_ds and save as csv\n",
    "df_test['predictions'] = predictions\n",
    "df_test.to_csv(f'../results/gbtm-auto-auto/gbtm-auto-auto-labeled-unweighted-{train_iteration}-PREDICTIONS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open csv file\n",
    "df_predictions = pd.read_csv(f'../results/gbtm-auto-auto/gbtm-auto-auto-labeled-unweighted-1-PREDICTIONS.csv', header=0)\n",
    "\n",
    "# get actual values from last column of csv file\n",
    "predictions = df_predictions['predictions'].tolist()\n",
    "actual = df_predictions['salary'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] == actual[i]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "accuracy = correct / len(predictions)\n",
    "\n",
    "print(\"Accuracy: \", accuracy, \"=\", correct, \"/\", str(len(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix\n",
    "confusion_matrix = confusion_matrix(actual, predictions)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification report\n",
    "class_report = classification_report(actual, predictions)\n",
    "print(class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
